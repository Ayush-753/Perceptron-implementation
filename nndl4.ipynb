{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "4. Design and implement a CNN model with 4+ layers of convolution to classify multicategory image datasets. Use the concept of regularization and dropout while designing CNN model. Use the fashion MNIST datset. Record the training accuracy corresponding to the following architecture:\n",
        "a. base model\n",
        "a. Model with L1 regularization\n",
        "c. Model with L2 regularization\n",
        "d. Model with dropout"
      ],
      "metadata": {
        "id": "v6oWGFUThjGp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, regularizers\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "(train_images, train_labels), (test_images, test_labels) = keras.datasets.fashion_mnist.load_data()\n",
        "train_images = np.expand_dims(train_images.astype('float32') / 255.0, axis=-1)\n",
        "test_images = np.expand_dims(test_images.astype('float32') / 255.0, axis=-1)\n",
        "train_labels = keras.utils.to_categorical(train_labels, 10)\n",
        "test_labels = keras.utils.to_categorical(test_labels, 10)\n",
        "\n",
        "train_images, val_images, train_labels, val_labels = train_test_split(train_images, train_labels, test_size=0.2)\n",
        "\n",
        "def create_model(regularization_type=None):\n",
        "    model = keras.Sequential([\n",
        "        layers.Input(shape=(28, 28, 1)),\n",
        "        layers.Conv2D(32, (3, 3), activation='relu'),\n",
        "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(128, activation='relu', kernel_regularizer=regularizers.l1(0.01) if regularization_type == 'l1' else (regularizers.l2(0.01) if regularization_type == 'l2' else None)),\n",
        "        layers.Dense(10, activation='softmax')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "def train_and_evaluate(model):\n",
        "    model.fit(train_images, train_labels, epochs=3, validation_data=(val_images, val_labels), verbose=0)\n",
        "    test_loss, test_acc = model.evaluate(test_images, test_labels, verbose=0)\n",
        "    return test_acc\n",
        "\n",
        "base_model = create_model()\n",
        "base_test_acc = train_and_evaluate(base_model)\n",
        "\n",
        "l1_model = create_model('l1')\n",
        "l1_test_acc = train_and_evaluate(l1_model)\n",
        "\n",
        "l2_model = create_model('l2')\n",
        "l2_test_acc = train_and_evaluate(l2_model)\n",
        "\n",
        "def create_model_dropout():\n",
        "    model = keras.Sequential([\n",
        "        layers.Input(shape=(28, 28, 1)),\n",
        "        layers.Conv2D(32, (3, 3), activation='relu'),\n",
        "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(128, activation='relu'),\n",
        "        layers.Dropout(0.5),\n",
        "        layers.Dense(10, activation='softmax')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "dropout_model = create_model_dropout()\n",
        "dropout_test_acc = train_and_evaluate(dropout_model)\n",
        "\n",
        "print(f\"Base Model Test Accuracy: {base_test_acc:.4f}\")\n",
        "print(f\"L1 Regularization Test Accuracy: {l1_test_acc:.4f}\")\n",
        "print(f\"L2 Regularization Test Accuracy: {l2_test_acc:.4f}\")\n",
        "print(f\"Dropout Model Test Accuracy: {dropout_test_acc:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0hQoA0uAhj6w",
        "outputId": "676a21af-6afc-4b5d-91bf-76926a6a2401"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "\u001b[1m29515/29515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "\u001b[1m26421880/26421880\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "\u001b[1m5148/5148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "\u001b[1m4422102/4422102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n",
            "Base Model Test Accuracy: 0.8943\n",
            "L1 Regularization Test Accuracy: 0.8063\n",
            "L2 Regularization Test Accuracy: 0.8681\n",
            "Dropout Model Test Accuracy: 0.8764\n"
          ]
        }
      ]
    }
  ]
}